from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from openai import OpenAI
from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility
import os
from dotenv import load_dotenv

load_dotenv()

app = FastAPI()

# OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Milvus connection
MILVUS_HOST = os.getenv("MILVUS_HOST", "localhost")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")

# Define request model
class UserInput(BaseModel):
    text: str

# Connect to Milvus and setup collection
def setup_milvus():
    connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)
    
    # Define collection schema
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535)
    ]
    schema = CollectionSchema(fields=fields, description="text embeddings")
    
    # Create collection if not exists
    collection_name = "text_collection"
    if not utility.has_collection(collection_name):
        collection = Collection(name=collection_name, schema=schema)
        collection.create_index(field_name="embedding", index_params={"index_type": "IVF_FLAT", "metric_type": "L2", "params": {"nlist": 1024}})
    return Collection(collection_name)

collection = setup_milvus()

@app.post("/generate")
async def generate_response(user_input: UserInput):
    try:
        # Get embedding for input
        embedding_response = client.embeddings.create(
            input=user_input.text,
            model="text-embedding-ada-002"
        )
        embedding = embedding_response.data[0].embedding

        # Search for similar texts
        collection.load()
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
        results = collection.search(
            data=[embedding],
            anns_field="embedding",
            param=search_params,
            limit=3,
            output_fields=["text"]
        )

        # Prepare context from search results
        context = ""
        for hits in results:
            for hit in hits:
                context += hit.entity.get("text") + "\n"

        # Generate response using OpenAI
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful AI assistant."},
                {"role": "user", "content": f"Context: {context}\n\nUser input: {user_input.text}"}
            ]
        )

        # Store input in Milvus
        collection.insert([[embedding], [user_input.text]])
        print("HELLO!!!!!!")
        return {"response": response.choices[0].message.content}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.get("/hello")
def hello_world():
    print("HELLO!")